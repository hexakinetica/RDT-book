% ===================================================================
% Chapter 7: Architectural Patterns and Techniques in RDT
% ===================================================================

\chapter{Implementing Architectural Patterns and Techniques in RDT}
\label{chap:implementation_patterns_conceptual}


\begin{navigationbox}{In this chapter, you will learn:}
    \begin{itemize}
        \item To move from high-level diagrams to practical implementation by dissecting the "DNA" of the RDT codebase.
        \item How to implement \term{Strong Typing} to prevent entire classes of bugs at compile-time.
        \item How a thread-safe \term{Blackboard} pattern is realized using granular read-write locks (\hcode{std::shared\_mutex}).
        \item How the \term{Strategy} and \term{Factory Method} patterns enable a flexible and extensible motion planning system.
        \item The critical importance and implementation details of a \term{lock-free SPSC queue} for the RT/NRT bridge.
        \item How \term{Dependency Injection} and \term{RAII-based thread management} (\hcode{std::jthread}) lead to a modular, testable, and robust system.
    \end{itemize}
\end{navigationbox}

In the previous chapters, we designed our system and defined its components. Now, we will dissect its "DNA"—the key architectural patterns and engineering techniques that make our system robust and flexible. This chapter is a practical guide where each concept is explained in the context of the RDT project. We will answer the question of "HOW?" on a conceptual level, focusing on the trade-offs and reasoning behind each decision. For those who wish to dive into the C++ source code, detailed implementation analysis of each pattern is provided in Appendix~\ref{app:code_dissection}.

\section{Technique: Strong Typing as a First Line of Defense}
\label{sec:strong_typing_conceptual}

A reliable house begins with a solid foundation. The foundation of our software architecture is not its classes or algorithms, but its \textbf{type system}. Before writing any complex logic, we must first define the "alphabet" of our system: how we represent distance, angle, velocity, and pose. The most common path, especially during prototyping, is to use a primitive type like \hcode{double} for everything. This approach is simple, fast to implement, and universally compatible with mathematical libraries. It is also one of a system's greatest hidden liabilities.

A core architectural technique in RDT is the strict enforcement of strong, semantic typing for all physical quantities. This section explains the engineering rationale behind this deliberate choice.

\subsection{The Problem: The Semantic Ambiguity of Primitive Types}
\label{subsec:problem_of_double_conceptual}

The danger of using primitive types is not a matter of syntax, but of \textit{semantics}. A variable declared as \hcode{double angle = 90.0;} is semantically ambiguous. It carries a value, but it has no intrinsic meaning. A compiler sees it as just a 64-bit floating-point number. It has no way of knowing whether the programmer intended this to be 90 degrees or 90 radians. This ambiguity creates a fertile ground for two classes of subtle, yet potentially catastrophic, errors:

\begin{itemize}
    \item \textbf{Unit Mismatch Errors:} A function expecting an angle in radians is accidentally passed a value in degrees. This is not a theoretical problem; it is a recurring bug in robotics and aerospace that has led to spectacular failures. The Mars Climate Orbiter was lost in 1999 precisely because one piece of software provided results in imperial units (pound-seconds) while another expected them in metric units (newton-seconds). The compiler, seeing only floating-point numbers, could not detect this semantic mismatch. In our world, passing 90 degrees to a function expecting radians would cause the robot to attempt a move to ~5156 degrees, resulting in an immediate, violent collision.
    
    \item \textbf{Incompatible Operations:} A programmer, tired after a long debugging session, accidentally adds a robot's TCP coordinate (in meters) to a time value (in seconds). The compiler will happily perform the addition, as both are represented by \hcode{double}. The resulting number will be syntactically valid but physically meaningless, introducing nonsensical data that corrupts the system's state and leads to unpredictable behavior that is incredibly difficult to trace back to its source.
\end{itemize}

These errors cannot be reliably caught by unit tests because they depend on the interaction of multiple, often distant, parts of the system. They are latent vulnerabilities waiting for a specific, untested code path to be executed.

\subsection{The Solution: Creating "Numbers with Meaning" in \hcode{Units.h}}
\label{subsec:numbers_with_meaning_conceptual}

The RDT architecture solves this problem by moving error detection from the runtime stage to the compile-time stage. We leverage the C++ type system to create our own distinct, non-interchangeable types for each physical quantity. Instead of raw numbers, our system operates with "numbers with meaning," where the meaning is enforced by the compiler.

The conceptual implementation, found in our \hcode{Units.h} file, is based on a common C++ technique for creating strongly-typed wrappers:
\begin{enumerate}
    \item \textbf{A Generic Wrapper Template:} We define a template class, \hcode{Unit<Tag>}, which encapsulates a \hcode{double} value. This class overloads standard arithmetic operators (\hcode{+}, \hcode{-}, etc.) to work with other instances of the \textit{same} \hcode{Unit<Tag>} type.
    
    \item \textbf{Unique Compile-Time Tags:} For each physical unit, we declare a unique, empty structure (e.g., \hcode{struct MeterTag\{\};}, \hcode{struct RadianTag\{\};}). These structures have no data and no runtime overhead; their only purpose is to provide a unique type parameter to the \hcode{Unit} template.
    
    \item \textbf{Type Aliases for Clarity:} We then create clear, readable type aliases like \hcode{using Meters = Unit<MeterTag>;} and \hcode{using Radians = Unit<RadianTag>;}.
\end{enumerate}

The result is that \hcode{Meters} and \hcode{Radians} are now two completely different types. They cannot be implicitly converted to one another, nor can they be mixed in arithmetic operations. The compiler becomes our vigilant partner, instantly flagging any attempt to do so as a type error.

To enhance readability and usability, our \hcode{Units.h} also implements \textbf{user-defined literals}. This allows an engineer to write code that is both safe and highly intuitive. The expression \hcode{10.5\_m} is not just more concise than \hcode{Meters(10.5)}; it's a clear, self-documenting statement of intent that reduces cognitive load and makes code reviews more effective.


Adopting this technique is a strategic architectural decision with profound benefits.

\begin{principlebox}{The Trade-Off: Upfront Complexity for Long-Term Reliability.}
    Let's be clear: this approach adds a layer of complexity. We have to create and maintain the \hcode{Units.h} header. When interacting with external libraries that expect raw \hcode{double} values, we must explicitly call a \hcode{.value()} method to extract the underlying number. This is the "price" we pay.
    
    However, the return on this investment is immense. We prevent a whole class of subtle, dangerous bugs from ever entering our codebase. An error caught by the compiler is an error that a developer never has to debug at 3 A.M. on a factory floor. In the context of systems that control expensive and potentially dangerous physical hardware, this is not just a good trade-off; it is an essential one. It is a hallmark of a mature engineering culture that prioritizes correctness and safety over initial development speed.
\end{principlebox}

Furthermore, this technique forces our code to become \textbf{self-documenting}. When a function signature is \hcode{void setSpeed(MetersPerSecond speed);}, there is zero ambiguity about what it expects. The types themselves become a form of precise, compiler-verified documentation that, unlike comments, can never become stale or outdated. This foundation of clear, unambiguous, and safe data types, defined in \hcode{Units.h} and assembled in \hcode{DataTypes.h}, is what allows us to build the rest of our complex system with a high degree of confidence.

\textit{For a detailed analysis of the C++ implementation using templates, \hcode{constexpr}, and user-defined literals, please refer to Appendix A.1.}

%\lipsum[1-2] % Placeholder text




% ===================================================================
% Section 7.2: Pattern: The Blackboard (Single Source of Truth)
% ===================================================================

\section{Pattern: The Blackboard (Single Source of Truth)}
\label{sec:pattern_blackboard_conceptual}

In our complex NRT-domain, multiple components need to collaborate. The \hcode{Adapter} needs to know the current robot pose to process a jog command. The \hcode{TrajectoryPlanner} needs to know the active tool. The GUI needs to display the robot's mode. This presents a fundamental architectural choice for managing communication.

\subsection{The Dilemma: Spaghetti Dependencies vs. Centralized State}
\label{subsec:spaghetti_vs_centralized}

The most direct approach is to allow components to call each other's methods. The \hcode{TrajectoryPlanner} could simply call \hcode{gui->getActiveToolName()}. This creates a "spaghetti" architecture—a tangled web of dependencies where everything is coupled to everything else. This design is brittle and untestable. A change in the GUI could break the planner, and testing the planner requires instantiating the entire GUI.

The alternative is to decouple components by introducing a centralized data store where they can share information without being directly aware of each other. This is the \textbf{Blackboard} architectural pattern, also known as a Single Source of Truth (SSOT). The risk of this approach is that the central blackboard can become a performance bottleneck if access to it is not managed carefully.

\subsection{Our Solution: The \hcode{StateData} "Information Hub"}
\label{subsec:statedata_solution}

In RDT, we implement the Blackboard pattern with our \textbf{\hcode{StateData}} class. It acts as a central, thread-safe "information hub" for the entire NRT-domain. Components do not talk to each other; they read from and write to the blackboard.
\begin{itemize}
    \item A component needing information (a "reader") actively \textbf{pulls} the current state from \hcode{StateData}.
    \item A component with new information (a "writer") \textbf{pushes} its result to \hcode{StateData}.
\end{itemize}
This completely decouples the components. The planner doesn't know where the active tool information came from (GUI, a network command), and the GUI doesn't know who calculated the current pose (the NRT-core, a simulation). They only know the contract of the \hcode{StateData} blackboard.

\begin{tipbox}{Solving the Bottleneck with Advanced Locking.}
    To prevent the central \hcode{StateData} object from becoming a performance bottleneck, its implementation uses two crucial techniques:
    \begin{enumerate}
        \item \textbf{Fine-Grained Locking:} Instead of one global mutex, it uses a separate mutex for each logical piece of data (e.g., one for the robot pose, another for the active tool). This allows different threads to access unrelated data in parallel without blocking each other.
        \item \textbf{Read-Write Locks (\hcode{std::shared\_mutex}):} Since reading state is a much more frequent operation than writing it, we use a read-write lock. This allows any number of "readers" to access the data concurrently. Access is only exclusively locked for the brief moment a "writer" needs to update a value.
    \end{enumerate}
    These techniques ensure that our centralized state is both consistent and highly performant, combining the benefits of decoupling with minimal overhead.
\end{tipbox}

\paragraph{Architectural Justification}
Why choose the "pull" model of a Blackboard over a "push" model of an event bus (Publish-Subscribe) for the core system state? Control. A component like the \hcode{TrajectoryPlanner} needs to get a consistent snapshot of the entire system state \textit{at the exact moment it begins its calculation}. With a Blackboard, it can actively query for all the data it needs. In a Pub/Sub model, it would have to passively wait for multiple different events to arrive, which complicates ensuring data consistency and predictable execution flow. The Blackboard pattern gives our core components deterministic control over their data access, which is paramount.

\textit{For a detailed analysis of the thread-safe implementation using \hcode{std::shared\_mutex}, lock guards, and the \hcode{mutable} keyword, see Appendix A.2.}

% ===================================================================
% Section 7.3: Pattern: The Adapter
% ===================================================================

\section{Pattern: The Adapter}
\label{sec:pattern_adapter_conceptual}

Our system architecture is composed of two distinct technological stacks: a powerful, multi-threaded C++ core that handles all the robotics logic, and an independent set of GUI components built using the Qt framework. These two worlds are fundamentally incompatible. The C++ core is unaware of Qt's signals, slots, and event loop. The Qt components have no direct knowledge of the methods or state management within our C++ objects. A bridge is needed to connect these two different worlds, translating messages and events from one to the other.

This is the classic use case for the \textbf{Adapter} design pattern. Its purpose is to convert the interface of one system into an interface that another system expects. In our RDT project, the \textbf{\hcode{Adapter\_RobotController}} acts as this crucial bridge. It is the single, well-defined point of contact between the C++ backend and the Qt frontend, allowing them to collaborate without being tightly coupled.

\subsection{The Adapter's Dual Role: Listener and Broadcaster}
\label{subsec:adapter_dual_role_conceptual}

The Adapter works in two directions simultaneously. It acts as a "listener" for events originating from the GUI and as a "broadcaster" of state changes originating from the core.

\begin{enumerate}
    \item \textbf{From GUI to Core (The Listener):} The Adapter exposes Qt slots. When a user interacts with a GUI panel (e.g., clicks a button), the panel emits a Qt signal. The Adapter's slot is connected to this signal. Inside the slot, it translates the Qt-specific data (\hcode{QString}, \hcode{int}) into our strongly-typed C++ objects (\hcode{ToolFrame}, \hcode{AxisId}) and calls the appropriate method on the system core (\hcode{RobotController}).
    
    \item \textbf{From Core to GUI (The Broadcaster):} The Adapter periodically polls the system's shared state from the \hcode{StateData} object. If it detects any changes, it translates this new state information into a Qt signal and broadcasts it. Any interested GUI panels can connect their slots to this signal to update their displays.
\end{enumerate}

This bidirectional flow ensures a clean separation of concerns. The GUI knows how to display data and emit signals about user intent. The core knows how to execute commands and maintain its state. The Adapter is the dedicated translator in the middle.

\begin{figure}[h!]
    \centering
    \begin{infobox}{The Adapter as a Two-Way Bridge}
        \textbf{Conceptual Diagram of the Adapter's Bidirectional Data Flow}
        \vspace{0.5cm}
        

        GUI Panels ---(1. Qt Signal)---> [Adapter] ---(2. C++ Call)---> System Core \\
        (User Action)                                                     (e.g., RobotController) \\
        \\
        GUI Panels <---(4. Qt Signal)--- [Adapter] <---(3. Polling)---- System Core \\
        (State Update)                  (Compares state)             (e.g., StateData)

    \end{infobox}
    \caption{The Adapter acts as a bidirectional bridge. It listens for user actions from the GUI (1) and translates them into commands for the core (2). It also monitors the core's state (3) and broadcasts changes back to the GUI (4).}
    \label{fig:adapter_role_conceptual}
\end{figure}

\subsection{The Power of Polling and Caching}
\label{subsec:polling_caching_insight}

The most interesting architectural decision here is how information flows from the core to the GUI. A naive approach might be to have the core components directly emit events whenever their state changes. This would create a tight coupling between the core and the GUI's event system and, more dangerously, could lead to a "signal storm." If the robot's pose is updated every 2 ms, the core would flood the GUI with 500 signals per second, making the UI sluggish and unresponsive as it constantly tries to redraw.

The Adapter solves this using a more robust and efficient technique: \textbf{polling and caching}.
\begin{itemize}
    \item \textbf{Polling:} A \hcode{QTimer} triggers a slot in the Adapter at a reasonable frequency (e.g., 10-20 Hz).
    \item \textbf{Caching:} The Adapter reads the current state from \hcode{StateData} and compares it to a cached copy of the state from the previous poll.
    \item \textbf{Conditional Emission:} It emits update signals to the GUI \textit{only if} the state has actually changed.
\end{itemize}

\begin{principlebox}{Decoupling and Performance.}
    This polling mechanism completely decouples the core's update rate from the GUI's refresh rate. The core can run as fast as it needs to, while the GUI updates smoothly and efficiently. This design makes the GUI components completely passive and reactive; they only redraw when the Adapter explicitly tells them that the data they care about has changed. All the logic for change detection is centralized in the Adapter.
\end{principlebox}

Finally, for the Qt signal/slot system to handle our custom C++ types like \hcode{Pose}, we must register them with Qt's Meta-Object System using \hcode{Q\_DECLARE\_METATYPE}. This simple step makes our custom types first-class citizens in the Qt ecosystem.

\textit{For a detailed analysis of the Adapter's implementation, including slot connections, the polling timer, and type registration, see Appendix A.3.}

% ===================================================================
% Section 7.4: Pattern: The Strategy
% ===================================================================

\section{Pattern: The Strategy}
\label{sec:pattern_strategy_conceptual}

An industrial robot must be a versatile tool, capable of performing various types of movements tailored to specific tasks. A \hcode{PTP} (Point-to-Point) joint move is needed for fast repositioning where the exact path doesn't matter. A \hcode{LIN} (Linear) move is essential for processes like welding or sealing, where the tool must follow a perfect straight line. A \hcode{CIRC} (Circular) move is required for creating precise arcs. In the future, we might want to add more sophisticated algorithms, such as smooth spline-based trajectories for high-quality surface finishing.

\subsection{The Problem: The Monolithic Planner}
\label{subsec:monolithic_planner_problem}

How can we design our planner to accommodate this growing family of movement algorithms? A naive approach would be to implement all the logic within a single, massive method inside the \hcode{TrajectoryPlanner}, using a large \hcode{switch} or \hcode{if-else} block based on the motion type.

This approach is a maintenance nightmare. The planner class becomes a "God Object" that knows the intimate details of every motion algorithm. Adding a new motion type, like a spline, would require modifying this central, complex class, increasing its size and the risk of introducing bugs into existing, working code. The class violates the Single Responsibility Principle and the Open/Closed Principle (it is not open for extension but closed for modification). We need a cleaner, more modular design.

\subsection{The Solution: Encapsulating Algorithms as Interchangeable Strategies}
\label{subsec:strategy_pattern_solution}

The \textbf{Strategy} design pattern offers an elegant solution. The core idea is to define a family of algorithms, encapsulate each one in its own separate class, and make them interchangeable. This allows the algorithm to vary independently from the client (the "Context") that uses it.

In our RDT architecture, each type of motion calculation is implemented as a distinct "strategy." The \hcode{TrajectoryInterpolator} acts as the "Context" that uses one of these strategies to generate the path points.

\paragraph{The \hcode{MotionProfile} Interface: A Contract for Movement}
The foundation of our implementation is the abstract base class \textbf{\hcode{MotionProfile}}. This class defines the common interface, or "contract," that all concrete motion strategies must adhere to. It declares a set of pure virtual methods that a client can use, regardless of the underlying algorithm. Any class that claims to be a motion profile strategy must be able to, for instance, report its total duration and calculate the robot's state at any given time \hcode{t}.

\paragraph{Concrete Strategies: \hcode{TrapProfileJoint} and \hcode{TrapProfileLIN}}
With the contract defined, we create separate classes for each specific algorithm, each inheriting from \hcode{MotionProfile}.
\begin{itemize}
    \item \textbf{\hcode{TrapProfileJoint}:} This class encapsulates all the mathematics for a simple, trapezoidal-profile move in joint space. It knows how to find the leading axis and scale joint velocities to ensure synchronized arrival. It implements the \hcode{interpolateJoints(double t)} method of the interface.
    
    \item \textbf{\hcode{TrapProfileLIN}:} This class encapsulates the more complex logic for a straight-line Cartesian move. It knows how to handle the linear interpolation of XYZ coordinates and the spherical linear interpolation (SLERP) of orientation using quaternions. It implements the \hcode{interpolateCartesian(double t)} method of the interface.
\end{itemize}

\paragraph{The Context: \hcode{TrajectoryInterpolator}}
The \hcode{TrajectoryInterpolator} is the client that uses these strategies. It holds a pointer to the abstract \hcode{MotionProfile} interface, not to any concrete class. When it needs to generate a point, it simply calls the appropriate method on its current strategy object, completely unaware of the specific mathematical details being executed.

\begin{tipbox}{Combining Patterns: The Factory Method for Strategy Creation.}
    Who decides which concrete strategy to create? The \hcode{TrajectoryInterpolator} itself does, in its \hcode{loadSegment(...)} method. Based on the \hcode{MotionType} from the incoming command, it uses a \hcode{switch} statement to instantiate the correct \hcode{MotionProfile} object (\hcode{TrapProfileJoint}, \hcode{TrapProfileLIN}, etc.). This is a classic implementation of the \textbf{Factory Method} pattern. It decouples the interpolator from the concrete strategy classes at the point of creation, centralizing the "object factory" in one place.
\end{tipbox}

\begin{figure}[h!]
\centering
\begin{infobox}{The Strategy Pattern in RDT}
\textbf{UML Class Diagram for Motion Strategies}
\begin{verbatim}
+------------------------+     +-----------------------+ 
| TrajectoryInterpolator |---->|   <<Interface>>       | 
| (Context/Factory)      |     |    MotionProfile      | 
| - current\_profile\_   |     | - duration()          | 
| - loadSegment()        |     | - interpolateJoints() | 
| - nextPoint()          |     | - interpolateCart()   | 
+------------------------+     +-----------------------+ 
                                          ^ 
                            (implements)   | 
          +------------+-------------------+ 
          |                                |                             
+----------------+  +--------------+  +---------------+
|TrapProfileJoint|  |TrapProfileLIN|  |(Future) Spline|
+----------------+  +--------------+  +---------------+
\end{verbatim}    
\end{infobox}
\caption{The relationship between the Context (\hcode{TrajectoryInterpolator}) and the family of Strategy classes. The Interpolator depends only on the abstract \hcode{MotionProfile} interface, allowing different strategies to be used interchangeably.}
\label{fig:strategy_pattern_conceptual}
\end{figure}

\begin{principlebox}{Extensibility through Pattern Combination.}
    This design makes our motion planning system remarkably flexible and easy to extend. To add support for a new motion type, like a spline trajectory, we simply create a new \hcode{SplineProfile} class that inherits from \hcode{MotionProfile} and add a new case to the factory method in \hcode{loadSegment}. No other part of the system—not the planner, not the core logic of the interpolator—needs to be modified. This is the true power of programming to an interface, not an implementation, and it is a core tenet of building software that is designed to evolve over time.

    \vspace{1em} % Добавим немного воздуха перед последней строкой
    \textit{For a detailed analysis of the \hcode{MotionProfile} hierarchy and the Factory Method implementation in \hcode{TrajectoryInterpolator.cpp}, see Appendix A.4.}
\end{principlebox}

% ===================================================================
% Section 7.5: Technique: Lock-Free Programming for the RT/NRT Bridge
% ===================================================================

\section{Technique: Lock-Free Programming for the RT/NRT Bridge}
\label{sec:lock_free_conceptual}

The data structure that bridges the real-time (RT) and non-real-time (NRT) domains is arguably the most critical junction in the entire architecture. A flaw here can compromise the determinism and safety of the whole system. The central challenge is to pass data between the NRT-planner thread and the RT-motion-manager thread safely and, most importantly, without blocking.

\subsection{The Problem: The Mortal Danger of Mutexes at the RT/NRT Boundary}
\label{subsec:mutex_danger_conceptual}

A programmer's first instinct for thread-safe communication is to use a standard mutex (\hcode{std::mutex}). This approach, while correct for general-purpose concurrent programming, is catastrophic for a hard real-time system due to a dreaded phenomenon called \textbf{priority inversion}.

Imagine a scenario with a mutex-protected queue between our low-priority NRT-planner and our high-priority RT-motion-manager:
\begin{enumerate}
    \item The high-priority RT-thread wakes up, locks the mutex to retrieve a command, but is then preempted by the OS scheduler before it can unlock.
    \item A medium-priority thread (e.g., a network stack) starts running.
    \item The low-priority NRT-thread now wants to push new commands, but it cannot, because it is blocked waiting for the mutex held by the sleeping RT-thread.
\end{enumerate}
The result is a complete inversion of system priorities: the highest-priority thread is stalled, waiting for the lowest-priority thread, which itself is being starved of CPU time by any medium-priority tasks. The RT-thread will miss its hard deadlines, the robot's motion will fail, and the system's watchdog timer will eventually trigger a fault.

\begin{dangerbox}{Unacceptable Blocking.}
    Any locking mechanism that can cause a high-priority thread to wait for a low-priority thread is fundamentally unacceptable at the RT/NRT boundary. The solution must be \textbf{lock-free}—it must guarantee that the threads can make progress independently, without ever blocking each other.
\end{dangerbox}

\subsection{The Solution: A Lock-Free SPSC Queue}
\label{subsec:lock_free_spsc_conceptual}

To solve this, RDT implements a specialized data structure: a \textbf{Single-Producer, Single-Consumer (SPSC) lock-free queue}, which is realized in our \hcode{TrajectoryQueue} class. It is designed for the specific scenario where one dedicated thread (the NRT-planner) is the sole producer, and another dedicated thread (the RT-motion-manager) is the sole consumer.

The design is based on a circular buffer (a simple array) and two independent, atomic indices: \hcode{head\_} for reading and \hcode{tail\_} for writing. The key insight is that the producer thread \textit{only ever modifies} the \hcode{tail\_} index, and the consumer thread \textit{only ever modifies} the \hcode{head\_} index. Since they never write to the same memory location, a traditional lock is not needed. The "magic" lies in how they safely read each other's index to check if the queue is full or empty. This is where memory ordering guarantees become critical.

\begin{principlebox}{Engineering Insight: The Critical Role of Memory Barriers.}
    Modern compilers and CPUs aggressively reorder instructions to optimize performance. In a lock-free context, this can be fatal. For example, the compiler could reorder the producer's code to update the \hcode{tail\_} index \textit{before} it actually writes the data into the buffer. To prevent this, we use explicit \textbf{memory barriers}.
    \begin{itemize}
        \item \textbf{Release Semantics:} When the producer stores the new \hcode{tail\_} index, it uses \hcode{std::memory\_order\_release}. This acts as a barrier, guaranteeing that all memory writes before it (i.e., writing the data to the buffer) are visible to other threads before the index update is.
        \item \textbf{Acquire Semantics:} When the consumer reads the \hcode{tail\_} index to check if the queue is empty, it uses \hcode{std::memory\_order\_acquire}. This guarantees that if it sees the new index, it is also guaranteed to see the data that was written before it.
    \end{itemize}
    This "acquire-release" pairing forms a synchronization handshake that ensures data is passed correctly and safely without locks. It is the fundamental mechanism that allows us to build a safe and non-blocking bridge between the chaotic NRT world and the deterministic RT world.
\end{principlebox}

\textit{For a detailed analysis of the C++ implementation of the SPSC queue using \hcode{std::atomic} and memory ordering, see Appendix A.5.}

%\lipsum[3-4]



% ===================================================================
% Section 7.6: Pattern: Dependency Injection
% ===================================================================

\section{Pattern: Dependency Injection}
\label{sec:pattern_dependency_injection_conceptual}

Components in a complex system must collaborate. Our \hcode{TrajectoryPlanner} needs a \hcode{KinematicSolver} to function. This collaboration creates a dependency. The way we manage these dependencies is a critical architectural decision that directly impacts the system's flexibility, modularity, and, most importantly, its testability.

\subsection{The Anti-Pattern: Hard-Coded Dependencies}
\label{subsec:hard_coded_dependencies_conceptual}

The most straightforward, but most damaging, approach is for a component to create its own dependencies internally. For instance, the \hcode{TrajectoryPlanner} could create its own \hcode{KdlKinematicSolver} instance in its constructor.

This approach, while seemingly simple, creates a hard-coded, rigid dependency. The \hcode{TrajectoryPlanner} becomes permanently welded to that specific implementation. This has two disastrous consequences:
\begin{itemize}
    \item \textbf{Inflexibility:} We cannot easily swap out the \hcode{KdlKinematicSolver} for a different, perhaps faster, solver without modifying the \hcode{TrajectoryPlanner}'s source code. The component ceases to be a general-purpose planner and becomes a highly specialized, non-reusable piece of logic.
    \item \textbf{Untestability:} This is the more severe problem. It becomes impossible to unit test the planner's logic in isolation. To even construct a \hcode{TrajectoryPlanner} object, we are forced to construct a full-blown \hcode{KdlKinematicSolver}. A unit test for the planner's logic inadvertently becomes a complex integration test for half the system.
\end{itemize}

\subsection{The Solution: Inversion of Control and Dependency Injection}
\label{subsec:inversion_of_control_conceptual}

The solution is to apply the \textbf{Inversion of Control (IoC)} principle. A component should \textit{not} control the creation of its dependencies; that control is inverted and moved to an external entity. The mechanism by which this is achieved is called \textbf{Dependency Injection (DI)}.

Instead of creating the solver itself, our \hcode{TrajectoryPlanner} declares that it \textit{requires} a component that fulfills the \hcode{KinematicSolver} contract. This dependency is then "injected" into it from the outside, typically via its constructor.

\begin{minted}{cpp}
class TrajectoryPlanner
{
public:
    TrajectoryPlanner(std::shared_ptr<KinematicSolver> solver, ...);
private:
    std::shared_ptr<KinematicSolver> solver_;
};
\end{minted}
\captionof{listing}{Conceptual Constructor with Dependency Injection.}
\label{lst:conceptual-constructor-di}

This design choice has profound architectural benefits. The \hcode{TrajectoryPlanner} now depends on an \textbf{abstract interface} (\hcode{KinematicSolver}), not a concrete class. It is completely decoupled from the implementation details of \hcode{KdlKinematicSolver}. The responsibility for creating the concrete solver instance is moved one level up, to a "composition root" (in our case, the \hcode{main()} function), which then injects it into the planner.

\begin{tipbox}{Engineering Insight: Managing Ownership with Smart Pointers.}
    When we inject dependencies, we must also manage their lifetime. If we used raw pointers, we would have to manually manage their deletion, which is error-prone. Modern C++ provides a much safer solution: \textbf{smart pointers}. In RDT, we use \hcode{std::shared\_ptr} for shared components like the solver or \hcode{StateData}, as multiple parts of the system need access to the same instance. This automatically manages the object's lifetime through reference counting. For dependencies with a single owner, like the \hcode{IMotionInterface} which is owned exclusively by the \hcode{MotionManager}, we use \hcode{std::unique\_ptr} to express this exclusive ownership. This use of smart pointers makes the ownership semantics of the architecture clear and prevents memory leaks by design.
\end{tipbox}


The most significant benefit of Dependency Injection is that it makes our system highly \textbf{testable}. Because the \hcode{TrajectoryPlanner} depends only on the \hcode{KinematicSolver} interface, we can create a "mock" or "fake" implementation of that interface during a unit test. For example, to test how the planner handles an IK failure, we can create a simple \hcode{MockFailingSolver} class that always returns a failure. We can then inject this mock object into the planner and assert that it correctly enters an error state. This allows us to test each component's logic in complete isolation, which is the foundation of a robust testing strategy.

\textit{For a detailed analysis of how DI is used in the constructors of \hcode{RobotController} and \hcode{TrajectoryPlanner}, and how a mock object is injected during a test, see Appendix A.6.}


% ===================================================================
% Section 7.7: Technique: RAII-based Thread Lifecycle Management
% ===================================================================

\section{Technique: RAII-based Thread Lifecycle Management}
\label{sec:technique_jthread_conceptual}

Many components in our control system, such as the \hcode{MotionManager} and the \hcode{RobotController}, need to run their main loops concurrently in the background. The natural C++ solution is to execute them in separate threads. However, managing the lifecycle of these threads—ensuring they are started cleanly and, more importantly, stopped safely—is a common source of subtle and severe bugs in concurrent applications.

\subsection{The Problem: The Danger of "Bare" Threads}
\label{subsec:danger_std_thread_conceptual}

The standard C++11 tool for threading, \hcode{std::thread}, is powerful but unforgiving. The C++ standard dictates that if an \hcode{std::thread} object is destroyed while the thread it represents is still "joinable" (i.e., potentially running), the program must call \hcode{std::terminate()}. This forces the programmer to manually ensure that \hcode{join()} (which waits for the thread to finish) is called on every possible code path before the object's destructor runs. Forgetting this call, especially in the presence of exceptions, is a common error that leads to abrupt program crashes.

The alternative, calling \hcode{detach()}, is often worse. It creates an "orphaned" thread that continues to run in the background even after its parent object has been destroyed. This orphaned thread may later attempt to access the destroyed object's members, leading to undefined behavior and mysterious, hard-to-debug crashes.

\subsection{The Solution: \hcode{std::jthread} and RAII for Threads}
\label{subsec:solution_jthread_conceptual}

The C++20 standard introduced \textbf{\hcode{std::jthread}} ("joining thread"), a modern solution that applies the fundamental C++ idiom of \textbf{RAII (Resource Acquisition Is Initialization)} to thread management. The principle is simple: the thread's lifecycle is tied to the lifetime of the \hcode{jthread} object. When the object is destroyed, its destructor is automatically invoked, which in turn automatically requests the thread to stop and then joins it. This guarantees a clean, orderly shutdown without the risk of crashes or orphaned threads.

But how does the destructor "tell" the thread's loop to stop? It uses a mechanism for \textbf{cooperative cancellation}.

\begin{tipbox}{Engineering Insight: Cooperative Cancellation with \hcode{std::stop\_token}.}
    Forcibly killing a thread from the outside is dangerous. The modern approach is cooperative: the thread is politely asked to stop, and it periodically checks for this request. \hcode{std::jthread} automates this. It is associated with a \hcode{std::stop\_source}. When the \hcode{jthread} is destroyed, it uses its \hcode{stop\_source} to signal a stop request.
    
    The function running in the thread receives a corresponding \textbf{\hcode{std::stop\_token}}. The main loop of the thread simply needs to check this token in its loop condition (e.g., \hcode{while(!token.stop\_requested())}). When a stop is requested, the loop terminates gracefully, allowing the thread to finish its work cleanly before exiting.
\end{tipbox}

\paragraph{Implementation in RDT}
In our architecture, both the \hcode{MotionManager} and the \hcode{RobotController} use a private \hcode{std::jthread} member to manage their background loops.
\begin{itemize}
    \item The \hcode{start()} method creates and launches the \hcode{jthread}, passing it the main loop function (e.g., \hcode{tick()}).
    \item The main loop function's primary condition is a check on the stop token.
    \item The \hcode{stop()} method explicitly requests a stop and joins the thread. Crucially, even if \hcode{stop()} is not called, the class's destructor will do this automatically, ensuring safety.
\end{itemize}

This technique transforms thread management from a manual, error-prone task into a declarative, safe, and robust process, freeing the developer to focus on the logic of the control loops themselves.

\textit{For a detailed analysis of the \hcode{std::jthread} member and the start/stop/tick logic in \hcode{MotionManager.cpp}, see Appendix A.7.}


% ===================================================================
% Section 7.8: Technique: Managing Complexity with a Two-Tier HAL Abstraction
% ===================================================================

\section{Technique: Managing Complexity with a Two-Tier HAL Abstraction}
\label{sec:two_tier_hal_conceptual}

Our Hardware Abstraction Layer (HAL), defined by the \hcode{IMotionInterface}, effectively decouples the system core from specific hardware. This is a significant architectural achievement. However, as systems grow in complexity and need to support a wider variety of hardware or communication protocols, even a well-defined single interface can start to accumulate too many responsibilities, potentially violating the Single Responsibility Principle (SRP).

\subsection{The Problem: The Single Interface with Multiple, Unrelated Responsibilities}
\label{subsec:hal_srp_violation_conceptual}

Consider our \hcode{UDPMotionInterface}. Its current responsibility is to allow the \hcode{MotionManager} to send commands and receive state from a robot over UDP. To do this, it must handle two distinct sets of concerns:
\begin{enumerate}
    \item \textbf{Protocol Logic (The "What"):} It needs to understand the structure of a \hcode{JointCommandFrame} and how to serialize it into a specific data format (e.g., an XML string). It also needs to know how to deserialize an incoming byte stream (also XML) back into a \hcode{RobotStateFrame}. This is about the \textit{content and format} of the messages.
    \item \textbf{Transport Logic (The "How"):} It needs to know how to manage a UDP socket, handle IP addresses and ports, and deal with the specifics of sending and receiving datagrams. This is about the \textit{physical transmission} of bytes.
\end{enumerate}
Bundling these two unrelated responsibilities into a single class makes it less flexible. If we want to change the data format from XML to a more efficient binary protocol like Protobuf, we have to modify \hcode{UDPMotionInterface}. If we want to communicate with a robot that uses a serial port instead of UDP, we'd have to create a new \hcode{SerialMotionInterface} and duplicate all the XML (or Protobuf) serialization logic. This indicates a less-than-optimal separation of concerns.

\subsection{The Solution: Decomposing the HAL into Logical and Physical Layers}
\label{subsec:two_tier_hal_solution_conceptual}

The RDT architecture addresses this by decomposing the HAL into two distinct layers of abstraction, each defined by its own interface:

\begin{enumerate}

    \item \hcode{IMotionInterface} (The Logical Contract) This higher-level interface remains focused on the \textit{semantics of robot control}. It defines methods like \hcode{sendCommand(JointCommandFrame)} and \hcode{readState()}. It dictates \textbf{what} information needs to be exchanged with a generic robot, but it explicitly does \textit{not} specify \textit{how} that information should be formatted or transmitted.
    
    \item \hcode{ITransport} (The Physical Contract) This new, lower-level interface is introduced to handle the \textit{physical transmission of data}. Its contract is very simple: it knows how to \hcode{send(std::vector<char>)} and \hcode{std::vector<char> receive()}. It is completely agnostic to the content of those bytes; it could be XML, JSON, Protobuf, or an encrypted stream. It only cares about getting bytes from point A to point B.
\end{enumerate}

\begin{figure}[h!]
    \centering
    \begin{infobox}{Conceptual Diagram of the Two-Tier HAL}
        \textbf{Interaction between Logical and Physical HAL Contracts}
        \begin{verbatim}
MotionManager ---calls---> IMotionInterface (Logical: "Send this Command")
                                     |
                                     Implemented by
                                     V
UDPMotionInterface --uses--> ITransport (Physical: "Send these Bytes")
(Serializes Command to Bytes)  |
                               Implemented by
                               V
UDPTransport (Manages Sockets, Sends/Receives Bytes)
        \end{verbatim}
    \end{infobox}
    \caption{The \hcode{UDPMotionInterface} acts as a bridge, translating logical robot commands into byte streams, which are then handled by a separate \hcode{ITransport} implementation for physical transmission.}
    \label{fig:two_tier_hal_conceptual}
\end{figure}

With this separation, our concrete implementation of the motion interface, such as \hcode{UDPMotionInterface}, changes its role. It no longer handles low-level socket programming directly. Instead, it becomes a \textbf{Composer} or an \textbf{Adapter} to the \hcode{ITransport} layer. It implements the logical \hcode{IMotionInterface} contract by:
\begin{enumerate}
    \item Performing the protocol-specific logic (e.g., serializing a \hcode{JointCommandFrame} to an XML byte stream).
    \item Delegating the physical transmission of those bytes to an injected \hcode{ITransport} object.
\end{enumerate}




This two-tier abstraction, while adding a small amount of structural complexity, provides enormous benefits in terms of flexibility and adherence to the Single Responsibility Principle.
\begin{itemize}
    \item \textbf{Independent Evolution of Protocol and Transport:} We can now change the data serialization format (e.g., from XML to Protobuf) by simply creating a new class that implements \hcode{IMotionInterface} (e.g., \hcode{ProtobufMotionInterface}) and uses the \textit{same} \hcode{UDPTransport} object. The transport layer remains untouched.
    \item \textbf{Independent Evolution of Transport and Protocol:} Conversely, if we need to support a new physical communication medium (e.g., a serial port or a shared memory segment), we create a new class that implements \hcode{ITransport} (e.g., \hcode{SerialTransport}). We can then reuse our existing \hcode{UDPMotionInterface} (which should perhaps be renamed to \hcode{XmlMotionInterface} to better reflect its sole responsibility) by injecting the new \hcode{SerialTransport} into it. The protocol logic remains untouched.
\end{itemize}

\begin{principlebox}{A Masterclass in SRP and Decoupling.}
    This explicit separation of "what to send" (the protocol, managed by \hcode{IMotionInterface} implementers) from "how to send it" (the transport, managed by \hcode{ITransport} implementers) is a powerful demonstration of the Single Responsibility Principle. It results in highly cohesive components and an extremely loosely coupled HAL. We can mix and match protocols and transports with minimal effort, creating a truly modular and future-proof architecture for hardware communication.
\end{principlebox}

\textit{For a detailed analysis of the \hcode{ITransport} interface and how \hcode{UDPMotionInterface} uses it for communication, see Appendix A.8.}


% ===================================================================
% Section 7.9: Technique: Dynamic HAL Implementation Switching (Simulator/Real Robot)
% ===================================================================

\section{Technique: Dynamic HAL Implementation Switching (Simulator/Real Robot)}
\label{sec:dynamic_hal_switching_conceptual}

One of the most powerful practical benefits of an architecture built upon abstract interfaces and dependency injection is the ability to swap out component implementations "on the fly," without restarting the entire application. In the context of robotics, the most valuable application of this technique is the ability to dynamically switch between an \textbf{internal simulator} (our \hcode{FakeMotionInterface}) and the interface to a \textbf{real physical robot} (our \hcode{UDPMotionInterface}).

\subsection{The Problem: The Inefficient "Develop-Simulate-Deploy" Cycle}
\label{subsec:inefficient_cycle_conceptual}

Consider the typical workflow for a robotics engineer developing a new motion program:
\begin{enumerate}
    \item The engineer writes and tests the program logic extensively using a simulator. This is safe and allows for rapid iteration.
    \item Once confident, they need to test it on the actual robot. In a traditional setup, this involves stopping the application, changing configuration files (e.g., to point to the real robot's IP address instead of the simulator's mock interface), and then restarting the entire control system.
    \item If a problem is found on the real robot, the process reverses: stop, reconfigure for simulator, restart, debug, then repeat.
\end{enumerate}
This cycle is time-consuming, error-prone, and significantly slows down the development and commissioning process. What if we could switch between simulation and reality with a single click, while the application is running?

\subsection{The Architectural Solution: Orchestrated Lifecycle Management of the HAL Dependency}
\label{subsec:orchestrated_lifecycle_conceptual}

Our RDT architecture enables exactly this. The key lies in how we manage the \hcode{IMotion Interface} dependency:
\begin{itemize}
    \item \textbf{Centralized Ownership:} The \hcode{RobotController} (our NRT-domain orchestrator) \textit{owns} the active \hcode{IMotionInterface} instance (typically via a \hcode{std::unique\_ptr}). It is responsible for its creation and destruction.
    \item \textbf{Dependency Injection:} The \hcode{MotionManager} (our RT-core) \textit{uses} an \hcode{IMotionInterface} but does not own it. It receives a pointer to the active interface from the \hcode{Robot Controller}.
    \item \textbf{Managed Lifecycle of the Consumer:} The \hcode{MotionManager} provides methods to safely stop (\hcode{stop()}) and start (\hcode{start()}) its real-time processing loop.
\end{itemize}

This setup allows the \hcode{RobotController} to orchestrate a "hot-swap" of the HAL implementation. The conceptual sequence of operations, typically initiated by a GUI command, is as follows:

\begin{enumerate}
    \item \textbf{Safe Shutdown of RT-Core:} The \hcode{RobotController} commands the \hcode{MotionManager} to stop its RT-cycle using its \hcode{stop()} method. This ensures that the \hcode{MotionManager} gracefully finishes its current tick and its thread joins, guaranteeing that it is no longer using the current \hcode{IMotionInterface} object.
    
    \item \textbf{Replacing the Implementation:} The \hcode{RobotController} then destroys the old \hcode{IMotionInterface} object (e.g., \hcode{FakeMotionInterface}) and creates a new instance of the desired type (e.g., \hcode{new UDPMotionInterface(config)}). The \hcode{std::unique\_ptr} handles the destruction and ownership transfer automatically.
    
    \item \textbf{Injecting the New Dependency:} The \hcode{RobotController} informs the \hcode{MotionManager} about the new HAL implementation by calling a dedicated setter method, e.g., \hcode{motion\_manager\_->setMotionInterface(new\_hal\_instance)}.
    
    \item \textbf{Re-initializing and Restarting:} The \hcode{RobotController} then commands the new \hcode{IMotionInterface} to establish its connection (e.g., \hcode{new\_hal\_instance->connect()}). If successful, it commands the \hcode{MotionManager} to restart its RT-cycle using \hcode{motion\_manager\_->start()}.
\end{enumerate}

The \hcode{MotionManager} now resumes its operation, but all its calls to \hcode{sendCommand()} and \hcode{readState()} are directed to the newly instantiated HAL object, seamlessly switching control from the simulator to the real robot, or vice-versa.

\begin{principlebox}{Engineering Insight: The Power of Abstracting the "Boundary".}
    This dynamic switching capability is a direct result of abstracting the boundary between our software and the external world (be it simulated or real). By programming to the \hcode{IMotionInterface} contract, the \hcode{MotionManager} and the rest of the core system remain completely agnostic to whether they are controlling a piece of code that mimics a robot or a network stack that talks to actual hardware. This abstraction is what provides such profound flexibility. It transforms the HAL from a mere "driver layer" into a strategic architectural enabler.
\end{principlebox}
% --- Continuation of 7.9 ---



The ability to dynamically switch between a high-fidelity internal simulator and the real hardware offers significant advantages throughout the project lifecycle:
\begin{itemize}
    \item \textbf{Rapid Iteration during Development:} Engineers can write a piece of logic, test it instantly in the fast and safe simulator, make adjustments, and then, with a single command, re-test it on the physical robot to verify real-world behavior. This drastically reduces the "compile-deploy-test" cycle time.
    \item \textbf{Safer Commissioning:} New or complex robot programs can be fully vetted in simulation before ever being run on expensive or potentially dangerous physical hardware. This allows for the early detection of gross errors (e.g., programming a collision, specifying an unreachable point) in a zero-risk environment.
    \item \textbf{Simplified Off-Site Development and Support:} An engineer can work on program logic or diagnose issues remotely using the simulator, which accurately reflects the software stack of the real controller. The same control program files and configuration can be used in both environments.
    \item \textbf{Enhanced Training Tools:} The control system itself can be used as a high-fidelity training platform by running it in simulation mode, allowing operators to familiarize themselves with the HMI and program execution without needing access to a physical robot.
\end{itemize}

While our RDT's \hcode{FakeMotionInterface} is a relatively simple kinematic simulator, the architectural pattern allows it to be replaced with a much more sophisticated physics-based simulation engine in the future, further enhancing the "digital twin" capabilities of the system without requiring changes to the core control logic.

\subsubsection{Summary of Section 7.9}
\label{subsubsec:section7_9_summary_conceptual}
Dynamic HAL implementation switching is a powerful technique that showcases the benefits of a well-designed, interface-based architecture.
\begin{itemize}
    \item \textbf{The Result:} RDT's architecture supports the ability to switch "on the fly" between an internal simulator and a real hardware interface, significantly streamlining development, testing, and commissioning.
    \item \textbf{Key Architectural Enablers:}
    \begin{itemize}
        \item Centralized ownership and lifecycle management of the HAL dependency by an orchestrator component (\hcode{RobotController}).
        \item A clear, managed lifecycle for the HAL consumer (\hcode{MotionManager}), allowing it to be safely stopped and restarted.
        \item Consistent use of Dependency Injection and programming to abstract interfaces (\hcode{IMotionInterface}).
    \end{itemize}
\end{itemize}
This feature transforms the simulator from a separate, offline tool into an integrated part of the live control system, blurring the lines between the virtual and physical worlds for the benefit of the engineer.








% ===================================================================
% Section 7.10: Pattern: The State Machine
% ===================================================================

\section{Pattern: The State Machine}
\label{sec:pattern_state_machine_conceptual_revised}

Many components within our RDT system, particularly those with complex lifecycles or operational modes like \hcode{RobotController} and \hcode{MotionManager}, exhibit \textbf{stateful behavior}. This means their response to a given event or method call depends not only on the input parameters but also on their current internal state. For example, the \hcode{RobotController} will react differently to a \hcode{newMotionCommand()} if it's currently \hcode{Idle} versus if it's already \hcode{Moving} or in an \hcode{Error} state. Managing this stateful behavior robustly is a significant architectural challenge.

\subsection{The Problem: The Unmanageable Complexity of Implicit State Logic}
\label{subsec:implicit_state_problem_conceptual_revised}

A common, yet highly problematic, approach to managing state is to do so \textit{implicitly}. This typically involves a collection of boolean flags (\hcode{isInitializing}, \hcode{isMoving}, \hcode{hasError}, \hcode{isPaused}) and then weaving a complex tapestry of nested \hcode{if-else} statements throughout the component's methods to determine its current behavior based on the combination of these flags.

As the number of states and transitions grows, this approach rapidly becomes unmanageable:
\begin{itemize}
    \item \textbf{Lack of Clarity:} The overall logic is obscured, spread across multiple methods. It's difficult to get a holistic view of all possible states and how the component transitions between them.
    \item \textbf{High Risk of Bugs:} It's easy to miss a specific combination of flags or to handle a transition incorrectly, leading to inconsistent states or unexpected behavior. For instance, when an error occurs, one might set \hcode{hasError = true} but forget to reset \hcode{isMoving = false}, leaving the system in an invalid state.
    \item \textbf{Difficult Maintenance and Extension:} Adding a new state (e.g., a "Standby" mode) requires carefully reviewing and modifying numerous scattered conditional blocks, a process highly prone to introducing regressions.
    \item \textbf{Untestability:} It's nearly impossible to systematically test all valid and invalid state transitions because they are not explicitly defined.
\end{itemize}
This implicit state management turns the component into a "black box" whose internal logic is a minefield for developers.

\subsection{The Solution: Formalizing Behavior with an Explicit State Machine}
\label{subsec:state_machine_solution_conceptual_revised}

The \textbf{State Machine} pattern offers a structured and robust solution by making the state logic explicit and centralized. It is a behavioral design pattern that allows an object to alter its behavior when its internal state changes, making it appear as if the object has changed its class. The core of the pattern involves formally defining:
\begin{enumerate}
    \item \textbf{A finite set of States:} These are well-defined, mutually exclusive conditions the object can be in (e.g., \hcode{ControllerState::Idle}, \hcode{ControllerState::Moving}).
    \item \textbf{A set of Transitions:} These are the allowed paths from one state to another.
    \item \textbf{Events or Conditions (Guards):} These are the triggers that cause a transition to occur. An event might be an external method call (e.g., \hcode{emergencyStop()}), while a condition might be an internal check (e.g., \hcode{isCommandQueueEmpty()}).
\end{enumerate}

\paragraph{Implementation in RDT}
In our RDT architecture, both the \hcode{RobotController} (managing the NRT-domain's operational logic) and the \hcode{MotionManager} (managing the RT-domain's execution cycle) are conceptually designed and implemented as state machines.
\begin{itemize}
    \item Their current state is typically stored in a dedicated \hcode{enum class} member (e.g., \hcode{internal\_controller\_state\_} of type \hcode{ControllerState}).
    \item The logic for evaluating events/conditions and executing state transitions is centralized, usually within a specific method that is called repeatedly in the component's main processing loop (e.g., \hcode{RobotController::syncInternalState()} or within \hcode{MotionManager::tick()}).
\end{itemize}
For example, when the \hcode{RobotController} is in the \hcode{Idle} state, its \hcode{syncInternalState} method might check if a new motion task has been activated (\hcode{current\_motion\_task\_active\_ == true}). If so, it transitions to the \hcode{Moving} state. If it's in the \hcode{Moving} state, it checks if the task has completed (\hcode{current\_motion\_task\_active\_ == false}); if so, it transitions back to \hcode{Idle}. An \hcode{emergencyStop()} event from any state would transition it directly to an \hcode{Error} state.

\begin{figure}[h!]
    \centering
    \begin{infobox}{Conceptual State Machine for the \hcode{RobotController}}
        \textbf{Simplified UML State Diagram Illustrating Key States and Transitions}

        \begin{verbatim}
[*] --> Initializing : [on System Startup]
Initializing --> Idle : [on successful initialize() / InitOK]
Initializing --> Error : [on initialize() failure / InitFail]

Idle --> Moving : [executeMotionToTarget() called AND planning_success / NewMotionCmd]
Idle --> Error : [external_error_signal / SDOError]

Moving --> Moving : [processActiveMotionTask() / ContinueMotion]
Moving --> Idle : [isMotionTaskActive() == false AND NOT planner.hasError() / MotionDone]
Moving --> Error : [planner.hasError() == true OR rt_core_error / MotionFailOrRTError]

Error --> Idle : [clearError() called AND reset_command_received / ResetFromError]

(Any State) --> Error : [emergencyStop() called / EStop]
        \end{verbatim}
    \end{infobox}
     \vspace{0.3cm}
    \caption{A conceptual state diagram for the \hcode{RobotController}. Each box represents a state, and arrows represent transitions triggered by events or conditions. This visual tool is paramount for designing and understanding the component's behavior.}
    \label{fig:controller_state_machine_conceptual_revised}
\end{figure}

\begin{principlebox}{Engineering Insight: The Diagram as a Design and Verification Tool.}
    The true power of the State Machine pattern emerges when the state diagram (like Figure~\ref{fig:controller_state_machine_conceptual_revised}) is treated not just as after-the-fact documentation, but as the \textbf{primary design artifact}.
    \begin{itemize}
        \item \textbf{Design First:} Before writing complex conditional logic, the engineer first draws the state diagram. This forces a clear articulation of all states, all valid transitions, and the conditions that trigger them.
        \item \textbf{Visual Verification:} The diagram can be reviewed with colleagues to visually inspect for logical flaws, missing transitions, or unreachable states, long before any code is written.
        \item \textbf{Guided Implementation:} The C++ code that implements the state machine becomes a direct, almost mechanical, translation of the diagram. This dramatically reduces the risk of implementation errors.
        \item \textbf{Living Documentation:} The diagram serves as permanent, always-up-to-date documentation that accurately reflects the component's behavior. When a change is needed, the diagram is updated first, then the code.
    \end{itemize}
\end{principlebox}

By formalizing stateful behavior, the State Machine pattern transforms complex, error-prone conditional logic into a system that is explicit, predictable, verifiable, and far easier to maintain and extend.

\textit{For a conceptual look at the state transition logic within \hcode{RobotController::syncInternalState()} and the state management within \hcode{MotionManager::tick()}, refer to Appendix A.9.}

%\lipsum[1] % Placeholder for additional text if needed






